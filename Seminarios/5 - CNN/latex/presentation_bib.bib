%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Junior Moura at 2016-02-18 20:03:04 -0200 


%% Saved with string encoding Unicode (UTF-8) 

@book{geron2022hands,
  title={Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow},
  author={G{\'e}ron, Aur{\'e}lien},
  year={2022},
  publisher={" O'Reilly Media, Inc."}
}

@article{gliozzi2022combining,
  title={Combining neural and symbolic approaches to solve the Picasso problem: A first step},
  author={Gliozzi, Valentina and Pozzato, Gian Luca and Valese, Alberto},
  journal={Displays},
  volume={74},
  pages={102203},
  year={2022},
  publisher={Elsevier}
}

@article{sabour2017dynamic,
  title={Dynamic routing between capsules},
  author={Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{kosiorek2019stacked,
  title={Stacked capsule autoencoders},
  author={Kosiorek, Adam and Sabour, Sara and Teh, Yee Whye and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{mazzia2021efficient,
  title={Efficient-capsnet: Capsule network with self-attention routing},
  author={Mazzia, Vittorio and Salvetti, Francesco and Chiaberge, Marcello},
  journal={Scientific reports},
  volume={11},
  number={1},
  pages={14634},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{mukhometzianov2018capsnet,
  title={CapsNet comparative performance evaluation for image classification},
  author={Mukhometzianov, Rinat and Carrillo, Juan},
  journal={arXiv preprint arXiv:1805.11195},
  year={2018}
}

@misc{mingwei_li,
  author       = {{Mingwei Li}},
  title        = {{Understanding Capsule Networks}},
  howpublished = {\url{https://hdc.cs.arizona.edu/~mwli/understanding-capsule-network/writing/}},
  note         = {Acessado em: 04 de agosto de 2025},
  year         = {2024},
}

@article{kim2024capsule,
  title={Capsule Neural Networks as Noise Stabilizer for Time Series Data},
  author={Kim, Soyeon and Seong, Jihyeon and Han, Hyunkyung and Choi, Jaesik},
  journal={arXiv preprint arXiv:2403.13867},
  year={2024}
}

@inproceedings{hinton2018matrix,
  title={Matrix capsules with EM routing},
  author={Hinton, Geoffrey E and Sabour, Sara and Frosst, Nicholas},
  booktitle={International conference on learning representations},
  year={2018}
}

@article{grucaps,
  author       = {Prabod Rathnayaka and
                  Supun Abeysinghe and
                  Chamod Samarajeewa and
                  Isura Manchanayake and
                  Malaka J. Walpola},
  title        = {Sentylic at {IEST} 2018: Gated Recurrent Neural Network and Capsule
                  Network Based Approach for Implicit Emotion Detection},
  journal      = {CoRR},
  volume       = {abs/1809.01452},
  year         = {2018},
  url          = {http://arxiv.org/abs/1809.01452},
  eprinttype    = {arXiv},
  eprint       = {1809.01452},
  timestamp    = {Wed, 02 Jan 2019 12:29:31 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1809-01452.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{timecaps,
      title={TimeCaps: Capturing Time Series Data With Capsule Networks}, 
      author={Hirunima Jayasekara and Vinoj Jayasundara and Mohamed Athif and Jathushan Rajasegaran and Sandaru Jayasekara and Suranga Seneviratne and Ranga Rodrigo},
      year={2022},
      eprint={1911.11800},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1911.11800}, 
}

@article{lenet_lecun,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}}


@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{vggnet,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@InProceedings{googlenet,
    author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
    title = {Going Deeper With Convolutions},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2015}
}

@InProceedings{resnet,
    author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    title = {Deep Residual Learning for Image Recognition},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2016}
}

@InProceedings{densenet,
    author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
    title = {Densely Connected Convolutional Networks},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {July},
    year = {2017}
} 

@InProceedings{efficientnet,
  title = 	 {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author =       {Tan, Mingxing and Le, Quoc},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6105--6114},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/tan19a.html},
  abstract = 	 {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.}
}

@article{dumoulin2016guide,
  title={A guide to convolution arithmetic for deep learning},
  author={Dumoulin, Vincent and Visin, Francesco},
  journal={arXiv preprint arXiv:1603.07285},
  year={2016}
}

@article{akhtar2020interpretation,
  title={Interpretation of intelligence in CNN-pooling processes: a methodological survey},
  author={Akhtar, Nadeem and Ragavendran, U},
  journal={Neural computing and applications},
  volume={32},
  number={3},
  pages={879--898},
  year={2020},
  publisher={Springer}
}

@article{DOSREIS2024113258,
title = {Deep learning, deconvolutional neural network inverse design of strut-based lattice metamaterials},
journal = {Computational Materials Science},
volume = {244},
pages = {113258},
year = {2024},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2024.113258},
url = {https://www.sciencedirect.com/science/article/pii/S0927025624004798},
author = {Francisco {Dos Reis} and Nikolaos Karathanasopoulos},
keywords = {Deep learning, Graphs, Neural networks, Genetic algorithm, Deconvolution},
abstract = {Machine learning techniques have furnished a new paradigm in the modeling and design of advanced materials, both in the forward prediction of their effective performance and in the inverse identification of designs that meet specific response targets. While numerous architected media with a diverse range of effective mechanical properties have been investigated thus far, the inverse design of beam-based metamaterials with non-uniform inner architectures that emerge as a consequence of evolutionary optimization processes remains a significant challenge. This contribution elaborates a deep learning, deconvolutional neural network based (DCNN) framework which, when combined with a comprehensive parameterization of discrete lattice spaces, enables the inverse engineering of stochastic lattice metamaterials that cover wide mechanical performance spaces. Auxetic, shear soft and stiff, nearly isotropic and highly anisotropic beam-based metamaterial designs are inversely identified, upon a direct request of their desired mechanical performance, without the need of a latent, condensed space representation. The DCNN model is capable of robustly generating beam-based lattice designs with target mechanical attributes that extend beyond those employed in the initial training domain.}
}

@misc{long2015fullyconvolutionalnetworkssemantic,
      title={Fully Convolutional Networks for Semantic Segmentation}, 
      author={Jonathan Long and Evan Shelhamer and Trevor Darrell},
      year={2015},
      eprint={1411.4038},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1411.4038}, 
}

@online{PytorchTransp,
  author = {{PyTorch Core Development Team}},
  title = {{nn.ConvTranspose2d}},
  organization = {PyTorch},
  url = {https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html},
  urldate = {2025-11-10},
  year = {2025}
}