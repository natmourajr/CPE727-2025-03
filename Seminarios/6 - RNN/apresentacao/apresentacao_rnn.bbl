\begin{thebibliography}{10}

\bibitem{hopfield1982}
J.~J. Hopfield, ``Neural networks and physical systems with emergent collective computational abilities,'' {\em Proceedings of the National Academy of Sciences}, vol.~79, no.~8, pp.~2554--2558, 1982.

\bibitem{jordan1986}
M.~I. Jordan, ``Attractor dynamics and parallelism in a connectionist sequential machine,'' in {\em Proceedings of the 8th Annual Conference of the Cognitive Science Society}, pp.~531--546, 1986.

\bibitem{elman1990}
J.~L. Elman, ``Finding structure in time,'' {\em Cognitive Science}, vol.~14, no.~2, pp.~179--211, 1990.

\bibitem{werbos1990}
P.~J. Werbos, ``Backpropagation through time: What it does and how to do it,'' {\em Proceedings of the IEEE}, vol.~78, no.~10, pp.~1550--1560, 1990.

\bibitem{hochreiter1991}
S.~Hochreiter, {\em Untersuchungen zu dynamischen neuronalen Netzen}.
\newblock PhD thesis, Technische Universit{\"a}t M{\"u}nchen, 1991.

\bibitem{hochreiter1997}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' {\em Neural Computation}, vol.~9, no.~8, pp.~1735--1780, 1997.

\bibitem{schuster1997}
M.~Schuster and K.~K. Paliwal, ``Bidirectional recurrent neural networks,'' {\em IEEE Transactions on Signal Processing}, vol.~45, no.~11, pp.~2673--2681, 1997.

\bibitem{graves2005}
A.~Graves and J.~Schmidhuber, ``Framewise phoneme classification with bidirectional lstm networks,'' in {\em Proceedings of the International Joint Conference on Neural Networks (IJCNN)}, pp.~2047--2052, 2005.

\bibitem{cho2014}
K.~Cho, B.~van Merri{\"e}nboer, {\c{C}}.~G{\"u}l{\c{c}}ehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio, ``Learning phrase representations using rnn encoder-decoder for statistical machine translation,'' {\em arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{chung2014}
J.~Chung, {\c{C}}.~G{\"u}l{\c{c}}ehre, K.~Cho, and Y.~Bengio, ``Empirical evaluation of gated recurrent neural networks on sequence modeling,'' {\em arXiv preprint arXiv:1412.3555}, 2014.

\bibitem{serdyuk2018}
D.~Serdyuk, N.~R. Ke, A.~Sordoni, A.~Trischler, C.~Pal, and Y.~Bengio, ``Twin networks: Matching the future for sequence generation,'' in {\em International Conference on Learning Representations (ICLR)}, 2018.
\newblock arXiv:1708.06742.

\bibitem{pascanu2013}
R.~Pascanu, T.~Mikolov, and Y.~Bengio, ``On the difficulty of training recurrent neural networks,'' in {\em Proceedings of the 30th International Conference on Machine Learning (ICML)}, pp.~1310--1318, 2013.

\bibitem{gal2016}
Y.~Gal and Z.~Ghahramani, ``A theoretically grounded application of dropout in recurrent neural networks,'' in {\em Advances in Neural Information Processing Systems (NeurIPS)}, pp.~1019--1027, 2016.
\newblock arXiv:1512.05287.

\bibitem{ba2016}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton, ``Layer normalization,'' {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{sutskever2014}
I.~Sutskever, O.~Vinyals, and Q.~V. Le, ``Sequence to sequence learning with neural networks,'' in {\em Advances in Neural Information Processing Systems (NeurIPS)}, pp.~3104--3112, 2014.

\bibitem{bahdanau2015}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly learning to align and translate,'' in {\em International Conference on Learning Representations (ICLR)}, 2015.
\newblock arXiv:1409.0473.

\bibitem{vaswani2017}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in {\em Advances in Neural Information Processing Systems (NeurIPS)}, pp.~5998--6008, 2017.

\bibitem{devlin2019_bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{radford2019_gpt2}
A.~Radford, J.~Wu, R.~Child, D.~Luan, D.~Amodei, and I.~Sutskever, ``Language models are unsupervised multitask learners,'' {\em OpenAI Technical Report}, 2019.

\bibitem{brown2020_gpt3}
T.~B. Brown {\em et~al.}, ``Language models are few-shot learners,'' {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{bommasani2021_foundation}
R.~Bommasani {\em et~al.}, ``On the opportunities and risks of foundation models,'' {\em arXiv preprint arXiv:2108.07258}, 2021.

\bibitem{huang2019_hierarchical_multilabel_text_classification}
W.~Huang, E.~Chen, Q.~Liu, Y.~Chen, Z.~Huang, Y.~Liu, Z.~Zhao, D.~Zhang, and S.~Wang, ``Hierarchical multi-label text classification: An attention-based recurrent network approach,'' in {\em Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM â€™19)}, pp.~1051--1060, 2019.

\end{thebibliography}
