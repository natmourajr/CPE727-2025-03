%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Junior Moura at 2016-02-18 20:03:04 -0200


%% Saved with string encoding Unicode (UTF-8)

@article{demulder2015,
title = {A survey on the application of recurrent neural networks to statistical language modeling},
journal = {Computer Speech and Language},
volume = {30},
number = {1},
pages = {61-98},
year = {2015},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2014.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S088523081400093X},
author = {Wim {De Mulder} and Steven Bethard and Marie-Francine Moens},
keywords = {Recurrent neural networks, Natural language processing, Language modeling, Speech recognition, Machine translation},
abstract = {In this paper, we present a survey on the application of recurrent neural networks to the task of statistical language modeling. Although it has been shown that these models obtain good performance on this task, often superior to other state-of-the-art techniques, they suffer from some important drawbacks, including a very long training time and limitations on the number of context words that can be taken into account in practice. Recent extensions to recurrent neural network models have been developed in an attempt to address these drawbacks. This paper gives an overview of the most important extensions. Each technique is described and its performance on statistical language modeling, as described in the existing literature, is discussed. Our structured overview makes it possible to detect the most promising techniques in the field of recurrent neural networks, applied to language modeling, but it also highlights the techniques for which further research is required.}
}

@inproceedings{mikolov2013,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Tomas Mikolov and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
  booktitle={International Conference on Learning Representations},
  year={2013},
  url={https://api.semanticscholar.org/CorpusID:5959482}
}

@article{bojanowski2016,
author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
year = {2016},
month = {07},
pages = {},
title = {Enriching Word Vectors with Subword Information},
volume = {5},
journal = {Transactions of the Association for Computational Linguistics},
doi = {10.1162/tacl_a_00051}
}

@inproceedings{kim2014,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1181/",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751"
}

@inproceedings{neculoiu2016,
    title = "Learning Text Similarity with {S}iamese Recurrent Networks",
    author = "Neculoiu, Paul  and
      Versteegh, Maarten  and
      Rotaru, Mihai",
    editor = "Blunsom, Phil  and
      Cho, Kyunghyun  and
      Cohen, Shay  and
      Grefenstette, Edward  and
      Hermann, Karl Moritz  and
      Rimell, Laura  and
      Weston, Jason  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 1st Workshop on Representation Learning for {NLP}",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-1617/",
    doi = "10.18653/v1/W16-1617",
    pages = "148--157"
}

@inproceedings{cer2017,
    title = "{S}em{E}val-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation",
    author = "Cer, Daniel  and
      Diab, Mona  and
      Agirre, Eneko  and
      Lopez-Gazpio, I{\~n}igo  and
      Specia, Lucia",
    editor = "Bethard, Steven  and
      Carpuat, Marine  and
      Apidianaki, Marianna  and
      Mohammad, Saif M.  and
      Cer, Daniel  and
      Jurgens, David",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S17-2001/",
    doi = "10.18653/v1/S17-2001",
    pages = "1--14",
    abstract = "Semantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in \textit{all language tracks}. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the \textit{STS Benchmark} is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017)."
}

@inproceedings{akiba2019,
author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
title = {Optuna: A Next-generation Hyperparameter Optimization Framework},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330701},
doi = {10.1145/3292500.3330701},
abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {2623â€“2631},
numpages = {9},
keywords = {machine learning system, hyperparameter optimization, black-box optimization, Bayesian optimization},
location = {Anchorage, AK, USA},
series = {KDD '19}
}
