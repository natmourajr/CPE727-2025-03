# Guia de Uso - Features Manuais para MLP

Este guia explica como usar features extraÃ­das manualmente (handcrafted features) para treinar o MLP.

## ğŸ“Š Features Implementadas

O extrator cria **81 features** divididas em 7 categorias:

### 1. **Intensidade (10 features)**
- MÃ©dia, desvio padrÃ£o, variÃ¢ncia
- MÃ­nimo, mÃ¡ximo, mediana
- Quartis (25%, 75%)
- Assimetria (skew) e curtose

### 2. **Histograma (16 features)**
- DistribuiÃ§Ã£o de intensidades em 16 bins

### 3. **GLCM - Textura (20 features)**
- Contraste, dissimilaridade, homogeneidade
- Energia, correlaÃ§Ã£o
- ASM (Angular Second Moment)
- Entropia
- Calculado em 4 direÃ§Ãµes (0Â°, 45Â°, 90Â°, 135Â°)

### 4. **LBP - Textura Local (10 features)**
- Local Binary Patterns
- Captura padrÃµes de textura em escala local

### 5. **Momentos de Hu (7 features)**
- Invariantes a rotaÃ§Ã£o, escala e translaÃ§Ã£o
- Ãšteis para anÃ¡lise de forma

### 6. **Gradiente (8 features)**
- Magnitude e direÃ§Ã£o do gradiente (Sobel)
- Laplaciano (segunda derivada)

### 7. **FFT - FrequÃªncia (10 features)**
- AnÃ¡lise de frequÃªncia espacial
- Energia em baixa, mÃ©dia e alta frequÃªncia

## ğŸš€ Como Usar

### Passo 1: Extrair Features do Dataset

```bash
# Extrair features do conjunto de treino
python data/extract_manual_features.py \
    --data-dir data/train \
    --output-dir data/features \
    --split train \
    --num-workers 4

# Extrair features do conjunto de validaÃ§Ã£o
python data/extract_manual_features.py \
    --data-dir data/val \
    --output-dir data/features \
    --split val \
    --num-workers 4

# Extrair features do conjunto de teste
python data/extract_manual_features.py \
    --data-dir data/test \
    --output-dir data/features \
    --split test \
    --num-workers 4
```

**Estrutura esperada dos dados:**
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Normal/
â”‚   â”‚   â”œâ”€â”€ img1.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ TB/
â”‚       â”œâ”€â”€ img1.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ Normal/
â”‚   â””â”€â”€ TB/
â””â”€â”€ test/
    â”œâ”€â”€ Normal/
    â””â”€â”€ TB/
```

**Arquivos gerados:**
```
data/features/
â”œâ”€â”€ train_features_manual.npy    # Features de treino [N, 81]
â”œâ”€â”€ train_labels_manual.npy      # Labels de treino [N]
â”œâ”€â”€ val_features_manual.npy      # Features de validaÃ§Ã£o
â”œâ”€â”€ val_labels_manual.npy
â”œâ”€â”€ test_features_manual.npy     # Features de teste
â”œâ”€â”€ test_labels_manual.npy
â””â”€â”€ class_names.txt              # Nomes das classes
```

### Passo 2: Treinar MLP com Features Manuais

```bash
# MLP Simples (recomendado para comeÃ§ar)
python experiments/train_mlp_manual.py \
    --features-dir data/features \
    --model-type simple \
    --epochs 200 \
    --batch-size 32 \
    --lr 0.001 \
    --dropout 0.3 \
    --normalize

# MLP Profundo (mais camadas)
python experiments/train_mlp_manual.py \
    --features-dir data/features \
    --model-type deep \
    --hidden-sizes 128 64 32 \
    --epochs 200 \
    --batch-size 32 \
    --lr 0.001 \
    --dropout 0.4 \
    --normalize
```

### Passo 3: Avaliar o Modelo

```bash
python experiments/evaluate_mlp.py \
    --checkpoint results/mlp_manual_TIMESTAMP/best_model.pth \
    --data-dir data/test \
    --mode two_stage \
    --features-path data/features \
    --save-dir results/evaluation_manual
```

## ğŸ“ˆ ComparaÃ§Ã£o: Manual vs Deep Learning

| Aspecto | Features Manuais | Features Deep (ResNet50) |
|---------|------------------|--------------------------|
| **NÃºmero de features** | 81 | 2048 |
| **Tempo de extraÃ§Ã£o** | ~0.1s/imagem | ~0.01s/imagem (GPU) |
| **Interpretabilidade** | âœ… Alta | âŒ Baixa |
| **Performance esperada** | 85-90% AUC | 93-96% AUC |
| **Requer GPU** | âŒ NÃ£o | âœ… Sim (recomendado) |
| **Tamanho do modelo** | Pequeno (~50KB) | Grande (~100MB) |

## ğŸ’¡ Quando Usar Features Manuais?

### âœ… Vantagens
- **Interpretabilidade**: VocÃª sabe exatamente o que cada feature representa
- **Menor complexidade**: Menos parÃ¢metros, treina mais rÃ¡pido
- **Sem GPU necessÃ¡ria**: Pode rodar em qualquer mÃ¡quina
- **AnÃ¡lise de features**: Pode identificar quais features sÃ£o mais importantes
- **Dataset pequeno**: Funciona melhor com poucos dados

### âŒ Desvantagens
- **Performance inferior**: Geralmente 5-10% menor AUC que deep learning
- **Engenharia manual**: Requer conhecimento do domÃ­nio
- **Menos flexÃ­vel**: Features fixas, nÃ£o aprendem automaticamente

## ğŸ”¬ AnÃ¡lise de Features

ApÃ³s treinar, vocÃª pode analisar quais features sÃ£o mais importantes:

```python
import numpy as np
from data.feature_extraction import ManualFeatureExtractor

# Carrega modelo treinado
# ... (cÃ³digo de carregamento)

# ObtÃ©m nomes das features
extractor = ManualFeatureExtractor()
feature_names = extractor.get_feature_names()

# Analisa importÃ¢ncia (exemplo com pesos da primeira camada)
weights = model.fc1.weight.data.cpu().numpy()
importance = np.abs(weights).mean(axis=0)

# Top 10 features mais importantes
top_indices = np.argsort(importance)[-10:]
for idx in top_indices[::-1]:
    print(f"{feature_names[idx]}: {importance[idx]:.4f}")
```

## ğŸ¯ Dicas de OtimizaÃ§Ã£o

1. **NormalizaÃ§Ã£o**: Sempre use `--normalize` para padronizar as features
2. **Dropout**: Comece com 0.3, aumente se houver overfitting
3. **Learning Rate**: 0.001 Ã© um bom ponto de partida
4. **Ã‰pocas**: 200 Ã©pocas geralmente Ã© suficiente
5. **Batch Size**: 32 funciona bem para a maioria dos casos

## ğŸ“Š Resultados Esperados

Com o dataset Shenzhen (~566 imagens):

| MÃ©trica | Valor Esperado |
|---------|---------------|
| AcurÃ¡cia | 85-90% |
| AUC-ROC | 0.87-0.92 |
| Sensibilidade | 82-88% |
| Especificidade | 88-92% |

## ğŸ”§ Testando o Extrator

Para testar se o extrator estÃ¡ funcionando:

```bash
python data/feature_extraction.py
```

Isso deve imprimir informaÃ§Ãµes sobre as 81 features extraÃ­das de uma imagem de teste.

## ğŸ“š ReferÃªncias

As features implementadas sÃ£o baseadas em:
- **GLCM**: Haralick et al. (1973) - Textural Features for Image Classification
- **LBP**: Ojala et al. (2002) - Multiresolution Gray-Scale and Rotation Invariant Texture Classification
- **Hu Moments**: Hu (1962) - Visual Pattern Recognition by Moment Invariants
