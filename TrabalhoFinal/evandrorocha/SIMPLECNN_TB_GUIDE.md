# Guia de Uso - SimpleCNN_TB (CNN Tradicional Otimizada)

Este guia explica como usar a **SimpleCNN_TB**, uma CNN tradicional otimizada especificamente para detecÃ§Ã£o de tuberculose.

## ğŸ¯ Por Que SimpleCNN_TB?

A SimpleCNN_TB foi projetada especificamente para o dataset Shenzhen (~566 imagens):

### âœ… Vantagens
- **Apenas ~500K parÃ¢metros** (vs 51M da SimpleCNN ou 25.6M da ResNet50)
- **Menor risco de overfitting** em datasets pequenos
- **Global Average Pooling** reduz drasticamente os parÃ¢metros
- **4 blocos convolucionais** capturam features em diferentes nÃ­veis
- **Performance esperada: 86-89% AUC**

### ğŸ“Š ComparaÃ§Ã£o

| Modelo | ParÃ¢metros | AUC Esperado | Ideal Para |
|--------|-----------|--------------|------------|
| LeNetStyle | 5.8M | 75-80% | Aprendizado |
| SimpleCNN | 51M | 82-86% | Dataset mÃ©dio |
| **SimpleCNN_TB** | **~500K** | **86-89%** | **TB (dataset pequeno)** |
| TraditionalCNN | 30M | 85-88% | Dataset grande |
| ResNet50 | 25.6M | 92-95% | Transfer learning |

## ğŸ—ï¸ Arquitetura

```
Input: [3, 224, 224]
    â†“
Bloco 1: Conv(32) â†’ BatchNorm â†’ ReLU â†’ MaxPool [32, 112, 112]
    â†“ (Detecta bordas e texturas bÃ¡sicas)
Bloco 2: Conv(64) â†’ BatchNorm â†’ ReLU â†’ MaxPool [64, 56, 56]
    â†“ (Detecta padrÃµes de infiltrados pulmonares)
Bloco 3: Conv(128) â†’ BatchNorm â†’ ReLU â†’ MaxPool [128, 28, 28]
    â†“ (Detecta lesÃµes e nÃ³dulos)
Bloco 4: Conv(256) â†’ BatchNorm â†’ ReLU â†’ MaxPool [256, 14, 14]
    â†“ (Detecta cavitaÃ§Ãµes e estruturas complexas)
Global Average Pooling: [256, 14, 14] â†’ [256, 1, 1]
    â†“
FC1: 256 â†’ 128 â†’ ReLU â†’ Dropout(0.4)
    â†“
FC2: 128 â†’ 64 â†’ ReLU â†’ Dropout(0.2)
    â†“
FC3: 64 â†’ 2 (Normal/TB)
```

## ğŸš€ Como Usar

### 1. InstalaÃ§Ã£o

```bash
pip install -r requirements.txt
```

### 2. Organizar Dados

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Normal/
â”‚   â”‚   â”œâ”€â”€ img1.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ TB/
â”‚       â”œâ”€â”€ img1.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ Normal/
â”‚   â””â”€â”€ TB/
â””â”€â”€ test/
    â”œâ”€â”€ Normal/
    â””â”€â”€ TB/
```

### 3. Treinar

```bash
# SimpleCNN_TB (Recomendado para TB)
python experiments/train_cnn_traditional.py \
    --data-dir data \
    --model-type simple_tb \
    --epochs 150 \
    --batch-size 16 \
    --lr 0.0001 \
    --dropout 0.4

# SimpleCNN (VersÃ£o original)
python experiments/train_cnn_traditional.py \
    --data-dir data \
    --model-type simple \
    --epochs 150 \
    --batch-size 16 \
    --lr 0.0001 \
    --dropout 0.3

# TraditionalCNN (Mais profunda)
python experiments/train_cnn_traditional.py \
    --data-dir data \
    --model-type traditional \
    --epochs 150 \
    --batch-size 16 \
    --lr 0.0001 \
    --dropout 0.5
```

### 4. Avaliar

```bash
python experiments/evaluate_mlp.py \
    --checkpoint results/cnn_simple_tb_*/best_model.pth \
    --data-dir data/test \
    --mode end_to_end \
    --save-dir results/evaluation_cnn
```

## âš™ï¸ HiperparÃ¢metros Recomendados

### Para Dataset Shenzhen (~566 imagens)

```python
# ConfiguraÃ§Ã£o otimizada
epochs = 150              # Suficiente para convergir
batch_size = 16          # Pequeno para dataset pequeno
learning_rate = 0.0001   # Conservador
weight_decay = 1e-4      # RegularizaÃ§Ã£o L2
dropout = 0.4            # Previne overfitting
```

### Data Augmentation (ESSENCIAL!)

```python
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),      # Flip horizontal
    transforms.RandomRotation(15),               # RotaÃ§Ã£o Â±15Â°
    transforms.ColorJitter(                      # Ajustes de cor
        brightness=0.2,
        contrast=0.2
    ),
    transforms.RandomAffine(                     # TranslaÃ§Ã£o
        degrees=0,
        translate=(0.1, 0.1)
    ),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
```

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas

| MÃ©trica | Valor Esperado |
|---------|---------------|
| AcurÃ¡cia | 85-88% |
| AUC-ROC | 86-89% |
| Sensibilidade | 83-87% |
| Especificidade | 87-90% |

### Arquivos Gerados

```
results/cnn_simple_tb_TIMESTAMP/
â”œâ”€â”€ best_model.pth              # Melhor modelo (maior AUC)
â”œâ”€â”€ last_model.pth              # Ãšltimo modelo
â”œâ”€â”€ training_history.png        # GrÃ¡ficos de treinamento
â”œâ”€â”€ history.json                # HistÃ³rico de mÃ©tricas
â””â”€â”€ args.json                   # Argumentos usados
```

## ğŸ”¬ DiferenÃ§as Principais

### SimpleCNN vs SimpleCNN_TB

| CaracterÃ­stica | SimpleCNN | SimpleCNN_TB |
|----------------|-----------|--------------|
| **Blocos Conv** | 3 | 4 |
| **Pooling Final** | Flatten | Global Average Pooling |
| **ParÃ¢metros** | ~51M | ~500K (100x menor!) |
| **FC Layers** | 2 | 3 (menores) |
| **Overfitting** | MÃ©dio-Alto | Baixo |
| **AUC Esperado** | 82-86% | 86-89% |

### Global Average Pooling

```python
# SimpleCNN (Flatten)
x = x.view(x.size(0), -1)  # [batch, 128*28*28] = [batch, 100352]
x = fc1(x)  # Precisa de 100352 * 512 = 51M parÃ¢metros!

# SimpleCNN_TB (GAP)
x = gap(x)  # [batch, 256, 14, 14] â†’ [batch, 256, 1, 1]
x = x.view(x.size(0), -1)  # [batch, 256]
x = fc1(x)  # Precisa de apenas 256 * 128 = 33K parÃ¢metros!
```

**Vantagens do GAP:**
- âœ… Reduz drasticamente parÃ¢metros
- âœ… Menos overfitting
- âœ… Mais robusto a variaÃ§Ãµes de posiÃ§Ã£o
- âœ… Usado em arquiteturas modernas (ResNet, Inception)

## ğŸ’¡ Dicas de OtimizaÃ§Ã£o

### 1. Se Overfitting (val_loss aumenta)
```bash
# Aumente dropout
--dropout 0.5

# Aumente weight decay
--weight-decay 5e-4

# Mais data augmentation
# (edite train_cnn_traditional.py)
```

### 2. Se Underfitting (train_loss alto)
```bash
# Diminua dropout
--dropout 0.3

# Aumente learning rate
--lr 0.0005

# Treine por mais Ã©pocas
--epochs 200
```

### 3. Para Melhor Performance
```bash
# Use ensemble de 3-5 modelos
# Treine com seeds diferentes e faÃ§a mÃ©dia das prediÃ§Ãµes
```

## ğŸ“ ComparaÃ§Ã£o com ResNet50

| Aspecto | SimpleCNN_TB | ResNet50 |
|---------|--------------|----------|
| **Arquitetura** | Sequencial | Skip connections |
| **Profundidade** | 4 camadas conv | 50 camadas |
| **ParÃ¢metros** | ~500K | ~25.6M |
| **Performance** | 86-89% AUC | 92-95% AUC |
| **Treino** | ~2-3 horas | ~4-6 horas |
| **Interpretabilidade** | â­â­â­â­ Alta | â­â­ MÃ©dia |
| **Overfitting** | â­â­ Baixo | â­ Muito baixo* |

*Com transfer learning

## ğŸ“š Uso no CÃ³digo

```python
from models.traditional_cnn import SimpleCNN_TB

# Criar modelo
model = SimpleCNN_TB(
    num_classes=2,
    dropout_rate=0.4
)

# Forward pass
output = model(images)  # [batch, 2]

# Extrair feature maps (para visualizaÃ§Ã£o)
features = model.get_feature_maps(images)
# features['block1']: [batch, 32, 112, 112]
# features['block2']: [batch, 64, 56, 56]
# features['block3']: [batch, 128, 28, 28]
# features['block4']: [batch, 256, 14, 14]
```

## ğŸ¯ RecomendaÃ§Ã£o Final

**Para seu trabalho de detecÃ§Ã£o de TB:**

1. **Treine SimpleCNN_TB** como baseline de CNN tradicional
2. **Treine ResNet50** (jÃ¡ no seu README) para comparaÃ§Ã£o
3. **Compare resultados** e analise trade-offs

Isso mostrarÃ¡:
- EvoluÃ§Ã£o de CNNs (tradicional â†’ moderna)
- Impacto de skip connections
- Trade-off entre complexidade e performance
