# Guia de Uso - MLP para DetecÃ§Ã£o de Tuberculose

Este guia explica como usar a implementaÃ§Ã£o do MLP para detecÃ§Ã£o de tuberculose em radiografias de tÃ³rax.

## ğŸ“‹ Estrutura de Arquivos

```
evandrorocha/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mlp.py                    # Arquiteturas MLP
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train_mlp.py             # Script de treinamento
â”‚   â””â”€â”€ evaluate_mlp.py          # Script de avaliaÃ§Ã£o
â””â”€â”€ data/
    â”œâ”€â”€ train/                    # Dados de treino
    â”‚   â”œâ”€â”€ Normal/
    â”‚   â””â”€â”€ TB/
    â”œâ”€â”€ val/                      # Dados de validaÃ§Ã£o
    â”‚   â”œâ”€â”€ Normal/
    â”‚   â””â”€â”€ TB/
    â””â”€â”€ test/                     # Dados de teste
        â”œâ”€â”€ Normal/
        â””â”€â”€ TB/
```

## ğŸš€ Como Usar

### 1. Preparar o Ambiente

```bash
# Instalar dependÃªncias
pip install torch torchvision numpy pandas matplotlib scikit-learn tqdm seaborn
```

### 2. Organizar os Dados

Organize suas imagens na estrutura acima. Cada pasta (train/val/test) deve conter subpastas com os nomes das classes (Normal e TB).

### 3. Treinar o Modelo

#### OpÃ§Ã£o A: Modo Two-Stage (Recomendado)

Este modo primeiro extrai features usando ResNet50, depois treina apenas o MLP. Ã‰ mais rÃ¡pido e eficiente.

```bash
python experiments/train_mlp.py \
    --data-dir data \
    --mode two_stage \
    --epochs 100 \
    --batch-size 32 \
    --lr 0.001 \
    --hidden-sizes 512 256 128 \
    --dropout 0.5 \
    --save-dir results
```

#### OpÃ§Ã£o B: Modo End-to-End

Este modo treina o feature extractor e o MLP juntos.

```bash
python experiments/train_mlp.py \
    --data-dir data \
    --mode end_to_end \
    --freeze-extractor \
    --epochs 100 \
    --batch-size 16 \
    --lr 0.0001 \
    --hidden-sizes 512 256 128 \
    --dropout 0.5 \
    --save-dir results
```

### 4. Avaliar o Modelo

```bash
# Para modelo two-stage
python experiments/evaluate_mlp.py \
    --checkpoint results/mlp_two_stage_TIMESTAMP/best_model.pth \
    --data-dir data/test \
    --mode two_stage \
    --save-dir results/evaluation

# Para modelo end-to-end
python experiments/evaluate_mlp.py \
    --checkpoint results/mlp_end_to_end_TIMESTAMP/best_model.pth \
    --data-dir data/test \
    --mode end_to_end \
    --save-dir results/evaluation
```

## ğŸ“Š ParÃ¢metros Importantes

### Arquitetura do MLP

- **`--hidden-sizes`**: Tamanhos das camadas ocultas
  - PadrÃ£o: `512 256 128`
  - Exemplo: `--hidden-sizes 1024 512 256` (MLP maior)
  - Exemplo: `--hidden-sizes 256 128` (MLP menor)

- **`--dropout`**: Taxa de dropout para regularizaÃ§Ã£o
  - PadrÃ£o: `0.5`
  - Valores tÃ­picos: 0.3 a 0.6

### Treinamento

- **`--epochs`**: NÃºmero de Ã©pocas
  - PadrÃ£o: `100`
  - Recomendado: 50-150

- **`--batch-size`**: Tamanho do batch
  - Two-stage: 32-64 (mais rÃ¡pido)
  - End-to-end: 16-32 (usa mais memÃ³ria)

- **`--lr`**: Learning rate
  - Two-stage: `0.001` (MLP aprende mais rÃ¡pido)
  - End-to-end: `0.0001` (mais conservador)

- **`--weight-decay`**: RegularizaÃ§Ã£o L2
  - PadrÃ£o: `1e-4`

## ğŸ“ˆ Resultados Esperados

ApÃ³s o treinamento, vocÃª encontrarÃ¡:

```
results/mlp_two_stage_TIMESTAMP/
â”œâ”€â”€ best_model.pth              # Melhor modelo (maior AUC)
â”œâ”€â”€ last_model.pth              # Ãšltimo modelo
â”œâ”€â”€ training_metrics.png        # GrÃ¡ficos de treinamento
â”œâ”€â”€ metrics.json                # HistÃ³rico de mÃ©tricas
â”œâ”€â”€ args.json                   # Argumentos usados
â”œâ”€â”€ train_features.npy          # Features de treino (two-stage)
â”œâ”€â”€ train_labels.npy
â”œâ”€â”€ val_features.npy            # Features de validaÃ§Ã£o (two-stage)
â””â”€â”€ val_labels.npy
```

ApÃ³s a avaliaÃ§Ã£o:

```
results/evaluation/
â”œâ”€â”€ evaluation_results.json     # Todas as mÃ©tricas
â”œâ”€â”€ confusion_matrix.png        # Matriz de confusÃ£o
â”œâ”€â”€ roc_curve.png              # Curva ROC
â”œâ”€â”€ test_features.npy          # Features de teste (two-stage)
â””â”€â”€ test_labels.npy
```

## ğŸ¯ MÃ©tricas Avaliadas

- **AcurÃ¡cia**: ProporÃ§Ã£o de prediÃ§Ãµes corretas
- **PrecisÃ£o**: ProporÃ§Ã£o de TBs preditos que sÃ£o realmente TB
- **Recall/Sensibilidade**: ProporÃ§Ã£o de TBs reais que foram detectados
- **Especificidade**: ProporÃ§Ã£o de normais reais que foram identificados
- **F1-Score**: MÃ©dia harmÃ´nica entre precisÃ£o e recall
- **AUC-ROC**: Ãrea sob a curva ROC (0.5 = aleatÃ³rio, 1.0 = perfeito)

## ğŸ’¡ Dicas

1. **Comece com Two-Stage**: Ã‰ mais rÃ¡pido e geralmente dÃ¡ bons resultados
2. **Monitore Overfitting**: Se val_loss aumentar enquanto train_loss diminui, aumente dropout
3. **Ajuste Learning Rate**: Se o modelo nÃ£o convergir, reduza o learning rate
4. **Experimente Arquiteturas**: Teste diferentes configuraÃ§Ãµes de `--hidden-sizes`
5. **Use Early Stopping**: O modelo salva automaticamente o melhor checkpoint

## ğŸ”¬ NÃºmero de VariÃ¡veis

O MLP usa **2048 features** extraÃ­das do ResNet50:
- Essas features capturam padrÃµes complexos das imagens
- SÃ£o muito mais eficientes que usar pixels diretamente
- Representam caracterÃ­sticas de alto nÃ­vel (texturas, formas, etc.)

## âš™ï¸ Testando a ImplementaÃ§Ã£o

Para verificar se tudo estÃ¡ funcionando:

```bash
# Teste os modelos
python models/mlp.py
```

Isso deve imprimir informaÃ§Ãµes sobre cada arquitetura e confirmar que nÃ£o hÃ¡ erros.

## ğŸ“š ReferÃªncias

- **Transfer Learning**: Usamos ResNet50 prÃ©-treinado no ImageNet
- **RegularizaÃ§Ã£o**: Dropout + Batch Normalization + Weight Decay
- **OtimizaÃ§Ã£o**: Adam optimizer com ReduceLROnPlateau scheduler
