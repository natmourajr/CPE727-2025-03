# Trabalho Final CPE727 - Aprendizado Profundo

Compara√ß√£o entre modelos generativos e discriminativos para classifica√ß√£o multiclasse em dois datasets: Fashion MNIST (imagens) e AG_NEWS (texto).

**Autor:** Miguel Fernandes de Sousa
**CRID:** 125074229
**Per√≠odo:** 2025/3

---

## üöÄ Quick Start

### Op√ß√£o 1: Docker (Mais Simples)

```bash
# Executar todos os experimentos
docker-compose up experiments

# Ver resultados no MLflow
docker-compose up mlflow
# Acesse http://localhost:5000
```

### Op√ß√£o 2: uv (Desenvolvimento Local)

```bash
# Instalar depend√™ncias
uv sync

# Executar experimentos
uv run run_experiments.py
```

---

## Estrutura do Projeto

```
trabalho_final_CPE727/
‚îú‚îÄ‚îÄ src/                          # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Implementa√ß√µes dos modelos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes_bernoulli.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes_multinomial.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logistic_softmax.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logistic_ovr.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gmm.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ random_forest.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hierarchical_classifier.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/            # Transforma√ß√µes de dados
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # Carregador Fashion MNIST
‚îÇ   ‚îú‚îÄ‚îÄ data_loader_agnews.py     # Carregador AG_NEWS (TF-IDF)
‚îÇ   ‚îú‚îÄ‚îÄ data_loader_agnews_tokenized.py  # Carregador AG_NEWS (LSTM)
‚îÇ   ‚îú‚îÄ‚îÄ models_deep.py            # Modelos CNN e LSTM
‚îÇ   ‚îú‚îÄ‚îÄ train.py                  # Treinamento baseline Fashion MNIST
‚îÇ   ‚îú‚îÄ‚îÄ train_agnews.py           # Treinamento baseline AG_NEWS
‚îÇ   ‚îú‚îÄ‚îÄ train_deep.py             # Treinamento deep learning
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_tuning.py  # Tuning Fashion MNIST
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_tuning_agnews.py  # Tuning AG_NEWS
‚îÇ   ‚îú‚îÄ‚îÄ final_evaluation.py       # Avalia√ß√£o final Fashion MNIST
‚îÇ   ‚îî‚îÄ‚îÄ final_evaluation_agnews.py  # Avalia√ß√£o final AG_NEWS
‚îú‚îÄ‚îÄ scripts/                      # Scripts organizados
‚îÇ   ‚îú‚îÄ‚îÄ baseline/                 # Experimentos baseline
‚îÇ   ‚îú‚îÄ‚îÄ deep_learning/            # Experimentos deep learning
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/               # Scripts de avalia√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ utilities/                # Utilit√°rios
‚îÇ   ‚îî‚îÄ‚îÄ eda/                      # An√°lise explorat√≥ria
‚îú‚îÄ‚îÄ eda/                          # Outputs da an√°lise explorat√≥ria
‚îú‚îÄ‚îÄ mlruns/                       # Experimentos MLflow
‚îú‚îÄ‚îÄ results/                      # Resultados e gr√°ficos
‚îú‚îÄ‚îÄ confusion_matrices_baseline/  # Matrizes de confus√£o baseline
‚îú‚îÄ‚îÄ v2_deep_apresentacao/         # Apresenta√ß√£o e relat√≥rio
‚îî‚îÄ‚îÄ pyproject.toml                # Depend√™ncias do projeto
```

## Datasets

### Fashion MNIST (Imagens)
- **Amostras:** 70.000 imagens (60k treino, 10k teste)
- **Dimensionalidade:** 28x28 pixels = 784 features
- **Classes:** 10 categorias de roupas (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)
- **Pr√©-processamento:** Normaliza√ß√£o min-max para [-1, 1] (ou [0, 1] para MultinomialNB)

### AG_NEWS (Texto)
- **Amostras:** 127.600 not√≠cias (120k treino, 7.6k teste)
- **Classes:** 4 categorias (World, Sports, Business, Sci/Tech)
- **Representa√ß√£o:**
  - **Baseline:** TF-IDF com 10.000 features, max_df=0.5, min_df=5
  - **LSTM:** Tokeniza√ß√£o word-level, vocabul√°rio 10.000 palavras, sequ√™ncias de 200 tokens

## Requisitos

### M√©todo 1: Docker (Recomendado)

Requer apenas Docker e Docker Compose instalados:

```bash
# Verificar instala√ß√£o do Docker
docker --version
docker-compose --version
```

### M√©todo 2: uv (Recomendado para desenvolvimento local)

```bash
# Instalar uv (package manager Python moderno)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Sincronizar depend√™ncias (cria .venv automaticamente)
uv sync
```

### M√©todo 3: pip/poetry (alternativa)

```bash
# Com pip
pip install torch torchvision scikit-learn numpy pandas matplotlib seaborn mlflow

# Com poetry
poetry install
```

## Como Executar os Experimentos

### Execu√ß√£o com Docker (M√©todo Recomendado)

#### Executar todos os experimentos

```bash
# Construir imagem e rodar todos os experimentos
docker-compose up experiments

# Visualizar resultados no MLflow UI (em outro terminal)
docker-compose up mlflow
# Acesse http://localhost:5000
```

#### Executar experimentos espec√≠ficos

```bash
# Apenas EDA
docker-compose run eda

# Apenas baseline (Fashion MNIST e AG_NEWS)
docker-compose --profile baseline up

# Apenas deep learning
docker-compose --profile deep up deep-learning

# Experimentos espec√≠ficos por dataset
docker-compose --profile baseline up baseline-fashion
docker-compose --profile baseline up baseline-agnews
```

#### MLflow UI standalone

```bash
docker-compose up mlflow
# Acesse http://localhost:5000
```

### Execu√ß√£o com uv (Desenvolvimento Local)

Todos os comandos abaixo devem ser executados com `uv run`:

#### Pipeline completo

```bash
# Executar todos os experimentos
uv run run_experiments.py

# Executar apenas Fashion MNIST
uv run run_experiments.py --dataset fashion_mnist

# Executar apenas AG_NEWS
uv run run_experiments.py --dataset ag_news

# Pular EDA
uv run run_experiments.py --skip-eda

# Apenas baseline (sem deep learning)
uv run run_experiments.py --skip-deep

# Apenas deep learning (sem baseline)
uv run run_experiments.py --skip-baseline
```

#### Experimentos individuais

##### 1. An√°lise Explorat√≥ria dos Dados (EDA)

Execute a an√°lise explorat√≥ria para entender os datasets:

```bash
# Fashion MNIST
uv run scripts/eda/fashion_mnist_eda.py

# AG_NEWS
uv run scripts/eda/ag_news_eda.py
```

Os outputs ser√£o salvos em `eda/outputs/`.

##### 2. Experimentos Baseline - Fashion MNIST

###### Fase 1: Otimiza√ß√£o de Hiperpar√¢metros

```bash
# Executar Grid Search CV para todos os modelos baseline
uv run src/hyperparameter_tuning.py
```

**Modelos avaliados:**
- Naive Bayes (Gaussiano, Bernoulli, Multinomial)
- Gaussian Mixture Models (GMM)
- Regress√£o Log√≠stica (Softmax e One-vs-Rest)
- Random Forest

**Hiperpar√¢metros otimizados:**
- **Naive Bayes:** var_smoothing ‚àà {1e-09, 1e-08, 1e-07, 1e-06, 1e-05}
- **GMM:** n_components ‚àà {1, 2, 3, 4}, covariance_type ‚àà {'full', 'diag'}
- **Logistic Regression:** C ‚àà {0.01, 0.1, 1.0, 10.0}
- **Random Forest:** n_estimators ‚àà {100, 200}, max_depth ‚àà {None, 10, 20}, max_features ‚àà {'sqrt', 'log2'}

#### Fase 2: Avalia√ß√£o Final

```bash
# Treinar modelos com melhores hiperpar√¢metros e avaliar no conjunto de teste
uv run src/final_evaluation.py
```

**Resultados esperados (Test Accuracy):**
- Logistic OvR: 83.50%
- Logistic Softmax: 83.40%
- Naive Bayes Multinomial: 65.55%
- Naive Bayes Bernoulli: 64.82%
- Naive Bayes Gaussiano: 59.10%

### 3. Experimentos Baseline - AG_NEWS

#### Fase 1: Otimiza√ß√£o de Hiperpar√¢metros

```bash
# Executar Grid Search CV para todos os modelos baseline
uv run src/hyperparameter_tuning_agnews.py
```

**Estrat√©gia em 2 fases** (para reduzir consumo de mem√≥ria):
- **Fase 1:** Quick test com 5k amostras, 2 folds (10 min)
- **Fase 2:** Refinamento com 30k amostras, 2 folds (40 min)

#### Fase 2: Avalia√ß√£o Final

```bash
# Treinar modelos com melhores hiperpar√¢metros e avaliar no conjunto de teste
uv run src/final_evaluation_agnews.py
```

**Resultados esperados (Test Accuracy):**
- Logistic OvR: 91.34%
- Logistic Softmax: 91.24%
- Random Forest: 90.96%
- Naive Bayes Multinomial: 89.66%
- Naive Bayes Bernoulli: 89.36%
- GMM: 86.89%
- Naive Bayes Gaussiano: 86.64%

### 4. Experimentos Deep Learning - CNN (Fashion MNIST)

#### Otimiza√ß√£o de Hiperpar√¢metros (2 est√°gios)

```bash
# Executar otimiza√ß√£o em 2 est√°gios
uv run src/train_deep.py --dataset fashion_mnist --mode grid_search
```

**Est√°gio 1 (Tiny - 500 amostras):**
- learning_rate ‚àà {0.001, 0.01}
- dropout ‚àà {0.3, 0.5}
- batch_size ‚àà {32, 64}
- epochs = 3

**Est√°gio 2 (Small - 5000 amostras):**
- learning_rate ‚àà {0.0005, 0.001, 0.002}
- dropout ‚àà {0.3, 0.4, 0.5}
- batch_size ‚àà {32, 64}
- epochs = 10

#### Treinamento Final

```bash
# Treinar modelo final com melhores hiperpar√¢metros (dataset completo)
uv run scripts/deep_learning/run_lenet_final.py
```

**Arquitetura CNN:**
- Conv1: 1‚Üí32 filtros 3x3, ReLU, MaxPool 2x2
- Conv2: 32‚Üí64 filtros 3x3, ReLU, MaxPool 2x2
- FC1: 1600‚Üí128, ReLU, Dropout
- FC2: 128‚Üí10 (sa√≠da)

**Hiperpar√¢metros finais:**
- learning_rate = 0.001
- dropout = 0.4
- batch_size = 32
- epochs = 20

**Resultado esperado:** Accuracy = 92.29%

#### Gerar Matriz de Confus√£o

```bash
uv run scripts/deep_learning/gen_confusion_fashion_cnn.py
```

### 5. Experimentos Deep Learning - LSTM (AG_NEWS)

#### Otimiza√ß√£o de Hiperpar√¢metros (2 est√°gios)

```bash
# Executar otimiza√ß√£o em 2 est√°gios
uv run src/train_deep.py --dataset ag_news --mode grid_search
```

**Est√°gio 1 (Tiny - 1000 amostras):**
- learning_rate ‚àà {0.001, 0.01}
- embedding_dim ‚àà {50, 100}
- hidden_dim ‚àà {64, 128}
- dropout ‚àà {0.3, 0.5}
- bidirectional ‚àà {False, True}
- batch_size ‚àà {32, 64}
- epochs = 3

**Est√°gio 2 (Small - 10000 amostras):**
- learning_rate ‚àà {0.005, 0.01}
- embedding_dim = 100
- hidden_dim ‚àà {64, 128}
- dropout ‚àà {0.2, 0.3, 0.4}
- bidirectional = True
- batch_size = 32
- epochs = 5

#### Treinamento Final

```bash
# Treinar modelo final com melhores hiperpar√¢metros (dataset completo)
uv run scripts/deep_learning/train_lstm_final_only.py
```

**Arquitetura LSTM:**
- Embedding: vocab_size (10000) ‚Üí embedding_dim (100)
- LSTM Bidirecional: embedding_dim ‚Üí hidden_dim (128)
- Dropout: 0.4
- FC: 2√óhidden_dim ‚Üí 4 classes

**Hiperpar√¢metros finais:**
- learning_rate = 0.005
- embedding_dim = 100
- hidden_dim = 128
- dropout = 0.4
- bidirectional = True
- batch_size = 32
- epochs = 20

**Resultado esperado:** Accuracy = 89.17%, tempo de treino ‚âà88.5 minutos

### 6. Executar Todos os Experimentos (Script Unificado)

```bash
# Executar pipeline completo
uv run run_experiments.py
```

Este script executar√° sequencialmente:
1. EDA para ambos datasets
2. Baseline Fashion MNIST (tuning + avalia√ß√£o)
3. Baseline AG_NEWS (tuning + avalia√ß√£o)
4. CNN Fashion MNIST (tuning + treinamento final)
5. LSTM AG_NEWS (tuning + treinamento final)

## Visualiza√ß√£o de Resultados

### MLflow UI

Todos os experimentos s√£o rastreados via MLflow:

```bash
mlflow ui
```

Acesse http://localhost:5000 para visualizar:
- M√©tricas de valida√ß√£o cruzada
- Hiperpar√¢metros testados
- Modelos salvos
- Artefatos (matrizes de confus√£o, curvas de aprendizado)

### An√°lise de Resultados

```bash
# Analisar resultados do MLflow
uv run scripts/evaluation/analyze_mlflow_results.py

# Verificar modelos faltantes
uv run scripts/evaluation/check_missing_models.py
```

## Principais Resultados

### Compara√ß√£o Baseline vs Deep Learning

| Dataset | Melhor Baseline | Deep Learning | Ganho |
|---------|----------------|---------------|-------|
| Fashion MNIST | 83.50% (Logistic OvR) | 92.29% (CNN) | +8.79 pp |
| AG_NEWS | 91.34% (Logistic OvR) | 89.17% (LSTM) | -2.17 pp |

### Insights Principais

1. **Modelos discriminativos superam generativos** em ambos datasets
2. **Gap maior em imagens** (17.95 pp) vs texto (1.68 pp)
3. **CNN superior para imagens** devido √† captura de features hier√°rquicas
4. **LSTM inferior a baseline em texto** (n√£o usa embeddings pr√©-treinados como BERT)
5. **Escolha da distribui√ß√£o importa:** MultinomialNB ‚âà BernoulliNB > GaussianNB
6. **Separa√ß√£o linear adequada** para TF-IDF (Logistic Regression > Random Forest)

## Troubleshooting

### Consumo de Mem√≥ria (AG_NEWS)

Se encontrar problemas de mem√≥ria com Random Forest:
- Usar estrat√©gia de 2 fases (5k ‚Üí 30k amostras)
- Desabilitar paralelismo aninhado (n_jobs=1 no modelo dentro do GridSearchCV)
- Reduzir n_jobs do GridSearchCV

### PyTorch

```bash
# Diagnosticar problemas PyTorch
bash scripts/utilities/diagnose_pytorch.sh

# Tentar fix autom√°tico
bash scripts/utilities/fix_pytorch.sh
```

## Refer√™ncias

1. Ng & Jordan (2002). On Discriminative vs. Generative Classifiers
2. Zheng et al. (2023). Revisiting Discriminative vs. Generative Classifiers
3. Bouzidi et al. (2024). CNNs and Vision Transformers for Fashion MNIST
4. Ozdemir (2024). News Classification with Deep Learning Methods

## Relat√≥rio Completo

Consulte o relat√≥rio completo em LaTeX:
```
v2_deep_apresentacao/relatorio/RELATORIO.tex
```

## Contato

Miguel Fernandes de Sousa
PEE/COPPE/UFRJ
CRID: 125074229
