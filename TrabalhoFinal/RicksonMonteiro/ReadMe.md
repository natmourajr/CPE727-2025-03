## ðŸŒ± What is the microfossil detection problem?

Microfossilsâ€”tiny remains of ancient organismsâ€”are essential for:

- geological dating

- paleoenvironment reconstruction

- reservoir analysis

- academic research

Traditionally, microfossil identification is manual, expert-dependent, and time-consuming.
This project aims to automate this process using object detection and classification models, trained over microscopy images annotated using tools like Label Studio.

Challenges include:

- inconsistent class names across experiments

- noisy or incomplete bounding boxes

- class imbalance

- multiple taxonomic categories

- multi-stage classification needs

## Directory Structure
```bash
project/
â”‚
â”œâ”€â”€ train.py # Entry point for training pipeline
â”œâ”€â”€ run.py # Optional launcher for dataset or train routines
â”œâ”€â”€ dataset.py # Dataset preparation (if needed)
â”‚
â”œâ”€â”€ configs/
â”‚ â”œâ”€â”€ training/
|   â”œâ”€â”€ full_cross_validation
â”‚   â”œâ”€â”€ retinanet.yaml
â”‚   â”œâ”€â”€ frcnn.yaml
â”‚   â”œâ”€â”€ ssdlite.yaml
â”‚   â””â”€â”€ dataset.yaml
â”‚
â”œâ”€â”€ experiments/ # Auto-generated logs / metrics / checkpoints
â”‚ â””â”€â”€ <model_name>/run_YYYY_MM_DD_HH_MM/
â”‚ â”œâ”€â”€ config.yaml
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ last.pth
â”‚ â”‚ â””â”€â”€ best.pth
â”‚ â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ core/
â”‚ â”‚ â””â”€â”€ config.py
â”‚
â”‚ â”œâ”€â”€ cross_validation/
â”‚ â”‚ â””â”€â”€ cross_validator.py
â”‚
â”‚ â”œâ”€â”€ pipeline/
â”‚ â”‚ â””â”€â”€ training_pipeline.py
â”‚ â”‚ â””â”€â”€ training_pipeline.py
â”‚ â”‚
â”‚ â”œâ”€â”€ trainer/
â”‚ â”‚ â”œâ”€â”€ frcnn_trainer.py
â”‚ â”‚ â”œâ”€â”€ retina_trainer.py
â”‚ â”‚ â””â”€â”€ ssd_trainer.py
â”‚ â”‚
â”‚ â”œâ”€â”€ dataset/
â”‚ â”‚ â”œâ”€â”€ coco_dataset.py
â”‚ â”‚ â””â”€â”€ ssd_dataset.py
â”‚ â”‚
â”‚ â””â”€â”€ ingestion/ 
â”‚   â”œâ”€â”€ zip_loader.py

â”‚ â”œâ”€â”€ preprocess/
â”‚ â”‚ â”œâ”€â”€ canonical/
â”‚ â”‚ â””â”€â”€ normalization/
â”‚ â”‚ â”œâ”€â”€ transformer/
â”‚ â”‚ â””â”€â”€ validation/
â”‚ â”‚ â”œâ”€â”€ dataset_builder.py
â”‚ â”‚ â”œâ”€â”€ parser.py
â”‚ â”‚ â””â”€â”€ harmonizer.py
â”‚   
â”œâ”€â”€ requirements_base.txt
â”œâ”€â”€ requirements_torch.txt
â”‚
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

## Usefull commands

## 

## Generate dataset
```bash
docker compose run marina python dataset.py --config configs/full_cross_validation
```
## Run Cross Validation
```bash
docker compose run marina python dataset.py --config configs/dataset.yaml
```

## Train RetinaNet
```bash
docker compose run marina python train.py --config configs/training/retinanet.yaml
```

## Train Faster R-CNN
```bash
docker compose run marina python train.py --config configs/training/frcnn.yaml
```


## Train SSD Lite
```bash
docker compose run marina python train.py --config configs/training/ssdlite.yaml
```
docker compose run marina python train.py --config configs/training/retinanet.yaml

## The result will be save at:

```bash
experiments/
    <model>/
        run_2025_01_01_12_30/
            config.yaml
            models/
                best.pth
                last.pth
            metrics.json
```